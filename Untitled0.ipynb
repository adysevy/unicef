{
 "metadata": {
  "name": "",
  "signature": "sha256:2a3e40b1281a396d4c7fee5fa511d966db7569829dfba0f26d157e4c2e8b33fe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from nltk.tag.stanford import NERTagger\n",
      "from nltk.tokenize.stanford import StanfordTokenizer\n",
      "import nltk\n",
      "\n",
      "# os.environ['JAVAHOME'] = 'C:/Program Files/Java/jdk1.8.0/bin/java.exe'\n",
      "\n",
      "#download the model files from http://nlp.stanford.edu/software/tagger.shtml#Download\n",
      "tokenizer = StanfordTokenizer('NER/stanford-postagger.jar') \n",
      "\n",
      "#download the model files from http://nlp.stanford.edu/software/CRF-NER.shtml#Download\n",
      "ner_tagger = NERTagger('NER/english.all.3class.distsim.crf.ser.gz',\n",
      "               'NER/stanford-ner.jar') \n",
      "\n",
      "#download with nltk.download() \n",
      "sent_tokenizer = nltk.data.load('NER/english.pickle')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_phrases(tagged_words):\n",
      "    tagged_phrases = []\n",
      "    i=0\n",
      "    while i<len(tagged_words):\n",
      "        w,t=tagged_words[i]\n",
      "        if t<>'O':\n",
      "            phrase=w\n",
      "            j=i+1\n",
      "            while j<len(tagged_words) and tagged_words[j][1]==t:\n",
      "                phrase+=' ' + tagged_words[j][0]\n",
      "                j+=1\n",
      "            i=j\n",
      "            tagged_phrases.append((phrase,t))\n",
      "        else:   \n",
      "            i+=1\n",
      "    return tagged_phrases\n",
      "\n",
      "def extract_entities(text):\n",
      "    entities = []\n",
      "    for sent in sent_tokenizer.tokenize(text):\n",
      "        tagged_words = ner_tagger.tag(sent.split())\n",
      "        entities += extract_phrases(tagged_words)\n",
      "    \n",
      "    return set(entities)\n",
      "\n",
      "   \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text ='''Chinese state media issued details Friday on 81 people sentenced on terror-related charges \u2014 nine\n",
      "of them to death \u2014 saying the bulk had belonged to terrorist organizations and committed murder and\n",
      "other violent crimes. The sentences issued Thursday came amid a massive crackdown in the western\n",
      "region of Xinjiang following four high-profile attacks on civilians since late October that have handed a\n",
      "major security challenge to President Xi Jinping during his first 15 months in office. The attacks have\n",
      "been blamed on extremists from the Xinjiang region's native Turkic-speaking Uighurs seeking to\n",
      "overthrow Chinese rule and inspired by global jihadi ideology.'''\n",
      "extract_entities(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{(u'Xi Jinping', u'PERSON'), (u'Xinjiang', u'LOCATION')}"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}