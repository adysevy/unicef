{
 "metadata": {
  "name": "",
  "signature": "sha256:177a0a5d77d6d9e74939760fbbd1e101bd1b1710453cb9237498d455dbc0f041"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from nltk.tag.stanford import NERTagger\n",
      "from nltk.tokenize.stanford import StanfordTokenizer\n",
      "import nltk\n",
      "\n",
      "# os.environ['JAVAHOME'] = 'C:/Program Files/Java/jdk1.8.0/bin/java.exe'\n",
      "\n",
      "#download the model files from http://nlp.stanford.edu/software/tagger.shtml#Download\n",
      "tokenizer = StanfordTokenizer('NER/stanford-postagger.jar') \n",
      "\n",
      "#download the model files from http://nlp.stanford.edu/software/CRF-NER.shtml#Download\n",
      "ner_tagger = NERTagger('NER/english.all.3class.distsim.crf.ser.gz',\n",
      "               'NER/stanford-ner.jar') \n",
      "\n",
      "#download with nltk.download() \n",
      "sent_tokenizer = nltk.data.load('english.pickle')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LookupError",
       "evalue": "Could not find stanford-postagger.jar jar file at /NER/stanford-postagger.jar",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-98bbaa4e435f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#download the model files from http://nlp.stanford.edu/software/tagger.shtml#Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/NER/stanford-postagger.jar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#download the model files from http://nlp.stanford.edu/software/CRF-NER.shtml#Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/adysevy/anaconda/lib/python2.7/site-packages/nltk/tokenize/stanford.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_to_jar, encoding, options, verbose, java_options)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0menv_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'STANFORD_POSTAGGER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0msearchpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stanford_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/adysevy/anaconda/lib/python2.7/site-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mfind_jar\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    642\u001b[0m         searchpath=(), url=None, verbose=True, is_regex=False):\n\u001b[1;32m    643\u001b[0m     return next(find_jar_iter(name_pattern, path_to_jar, env_vars,\n\u001b[0;32m--> 644\u001b[0;31m                          searchpath, url, verbose, is_regex))\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;31m##########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/adysevy/anaconda/lib/python2.7/site-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             raise LookupError('Could not find %s jar file at %s' %\n\u001b[0;32m--> 577\u001b[0;31m                             (name_pattern, path_to_jar))\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;31m# Check environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mLookupError\u001b[0m: Could not find stanford-postagger.jar jar file at /NER/stanford-postagger.jar"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_phrases(tagged_words):\n",
      "    tagged_phrases = []\n",
      "    i=0\n",
      "    while i<len(tagged_words):\n",
      "        w,t=tagged_words[i]\n",
      "        if t<>'O':\n",
      "            phrase=w\n",
      "            j=i+1\n",
      "            while j<len(tagged_words) and tagged_words[j][1]==t:\n",
      "                phrase+=' ' + tagged_words[j][0]\n",
      "                j+=1\n",
      "            i=j\n",
      "            tagged_phrases.append((phrase,t))\n",
      "        else:   \n",
      "            i+=1\n",
      "    return tagged_phrases\n",
      "\n",
      "def extract_entities(text):\n",
      "    entities = []\n",
      "    for sent in sent_tokenizer.tokenize(text):\n",
      "        tagged_words = ner_tagger.tag(sent.split())\n",
      "        entities += extract_phrases(tagged_words)\n",
      "    \n",
      "    return set(entities)\n",
      "\n",
      "   \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text ='''Chinese state media issued details Friday on 81 people sentenced on terror-related charges \u2014 nine\n",
      "of them to death \u2014 saying the bulk had belonged to terrorist organizations and committed murder and\n",
      "other violent crimes. The sentences issued Thursday came amid a massive crackdown in the western\n",
      "region of Xinjiang following four high-profile attacks on civilians since late October that have handed a\n",
      "major security challenge to President Xi Jinping during his first 15 months in office. The attacks have\n",
      "been blamed on extremists from the Xinjiang region's native Turkic-speaking Uighurs seeking to\n",
      "overthrow Chinese rule and inspired by global jihadi ideology.'''\n",
      "extract_entities(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{(u'Xi Jinping', u'PERSON'), (u'Xinjiang', u'LOCATION')}"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}